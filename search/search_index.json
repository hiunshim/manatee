{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to ManaTEE Project","text":"<p>ManaTEE is an open-source framework for secure data analytics in public research. It leverages Privacy Enhancing Technologies, including confidential computing, to protect sensitive data while maintaining usability.</p> <p>ManaTEE Project was initiated in 2024 as a core use case of TikTok. Now part of the Confidential Computing Consortium, ManaTEE addresses the growing challenges of balancing privacy, usability, and accuracy in enterprise data collaboration.</p>"},{"location":"#two-stage-data-analytics-platform","title":"Two-Stage Data Analytics Platform","text":"<p>ManaTEE introduces a two-stage data clean room model to provide an interactive interface for exploring data while protecting private data during processing. It combines different privacy-enhancing technologies (PETs) across two stages:</p> <ul> <li>Programming Stage: Data consumers explore datasets using low-risk data, employing different PETs such as pseudonymization or differentially private synthetic data generation.</li> <li>Secure Execution Stage: Workloads run in a trusted execution environment (TEE), which provides attestable integrity and confidentiality guarantees for the workload in the cloud.</li> </ul> <p></p> <p>Two-stage data clean room model</p>"},{"location":"#key-features","title":"Key Features","text":"<p>ManaTEE provides following key benefits:</p> <ul> <li>Interactive Programming: Integrated with Jupyter Notebook, allowing data consumers to work with Python and other popular languages.</li> <li>Cloud-Ready: ManaTEE can be easily deployed to existing cloud TEE backends such as Google Cloud. We plan to support other backends as well, eliminating the need to build the entire infrastructure from scratch.</li> <li>Flexible PET: Data providers can control the protection mechanisms at each stage to tailor to specific privacy requirements of the data.</li> <li>Trusted Execution Environment: By leveraging TEEs, ManaTEE ensures a high level of confidence in data confidentiality and program integrity for both data providers and data consumers.</li> <li>Accuracy and Utility: ManaTEE employs a two-stage design to ensure that result accuracy is not compromised for the sake of privacy.</li> </ul>"},{"location":"#use-cases","title":"Use Cases","text":"<p>Potential use cases for ManaTEE include:</p> <ul> <li>Trusted Research Environments (TREs): Secure data analysis for public health, economics, and more, while maintaining data privacy.</li> <li>Advertising &amp; Marketing: Lookalike segment analysis and private ad tracking without compromising user data.</li> <li>Machine Learning: Enables private model training without exposing sensitive data or algorithms.</li> </ul>"},{"location":"project-status/","title":"Project Status","text":"<p>We are releasing an alpha version, which may miss some necessary features.</p> Current (Alpha) Future Users One-Way Collaboration Multi-Way Collaboration Backend Single Backend (Goole Cloud Platform) Multiple Backend Data Provisioning Manual Automated Policy and Attestation Manual Automated Compute CPU CPU/GPU"},{"location":"developer/architecture/","title":"Architecture","text":""},{"location":"getting-started/building/","title":"Building","text":"<p>ManaTEE uses Bazel for hermetic builds. Bazel is aware of all required tools and dependencies, thus building images is as easy as:</p> <pre><code>bazel build //...\n</code></pre> <p>Find individual rules from corresponding <code>BUILD.bazel</code> files.</p>"},{"location":"getting-started/building/#components","title":"Components","text":"<p><code>app</code> directory contains the source codes of the data clean room which has three components:</p> <ul> <li><code>dcr_tee</code> contains tools that are used in the base image of stage2 such as a tool generates custom attestation report within GCP confidential space.</li> <li><code>dcr_api</code> is the backend service of the data clean room that processes the request from jupyterlab. </li> <li><code>dcr_monitor</code> is a cron job that monitors the execution of each job. The monitor is deployed to Kubernetes cluster and scheduled to run every minute.</li> <li><code>jupyterlab_manatee</code> is an JupyterLab extension for data clean room that submits a job on the fronted and queries the status of the jobs.</li> </ul>"},{"location":"getting-started/building/#loading-container-images","title":"Loading Container Images","text":"<p>If you'd like to load the images in your local container runtime (e.g., Docker), you can use <code>oci_load</code> rules.</p> <pre><code>bazel query 'kind(\"oci_load\", \"//app/...\")' | xargs -n1 bazel run\n</code></pre>"},{"location":"getting-started/building/#testing","title":"Testing","text":"<p>To run all tests, run:</p> <pre><code>bazel test //...\n</code></pre>"},{"location":"getting-started/deployment/","title":"GCP Deployment","text":""},{"location":"getting-started/deployment/#prerequisites","title":"Prerequisites","text":"<p>Currently, ManaTEE requires Google Cloud Platform (GCP) for deployment, as it requires cloud-provided TEE. In the future, we will support more cloud backends as well as local test deployment (See #31).</p> <p>Because of the cloud resource requirement, we recommend a cloud admin to create all the resources by following the steps below.</p>"},{"location":"getting-started/deployment/#cloud-setup","title":"Cloud Setup","text":"<ul> <li>A valid GCP account that has ability to create/destroy resources. For a GCP project, please enable the following apis:<ul> <li>serviceusage.googleapis.com</li> <li>compute.googleapis.com</li> <li>container.googleapis.com</li> <li>cloudkms.googleapis.com</li> <li>servicenetworking.googleapis.com</li> <li>cloudresourcemanager.googleapis.com</li> <li>sqladmin.googleapis.com</li> <li>confidentialcomputing.googleapis.com</li> </ul> </li> </ul>"},{"location":"getting-started/deployment/#tools","title":"Tools","text":"<ul> <li>Gcloud CLI Login to the GCP <code>gcloud auth login &amp;&amp; gcloud auth application-default login &amp;&amp; gcloud components install gke-gcloud-auth-plugin</code></li> <li>Terraform Terraform is an infrastructure as code tool that enables you to safely and predictably provision and manage infrastructure in any cloud.</li> <li>Helm Helm is a package manager for Kubernetes that allows developers and operators to more easily package, configure, and deploy applications and services onto Kubernetes clusters.</li> <li>Hertz Hertz is a high-performance, high-usability, extensible HTTP framework for Go. It\u2019s designed to make it easy for developers to build microservices.</li> </ul>"},{"location":"getting-started/deployment/#create-resources","title":"Create Resources","text":"<p>The resources are created and managed by the project administrator who has the <code>Owner</code> role in the GCP project. Make sure you have correctly defined environment variables in the <code>env.bzl</code>. Only the project administrator is responsible to run these commands to create resources.</p> <p><code>resources/global</code> directory contains the global resources including: clusters, cloud sql instance, database, docker repositories, and service accounts. These resource are global and only created once. <pre><code>pushd resources/global\n./apply.sh\npopd\n</code></pre></p> <p><code>resources/deployment</code> directory includes the resources releated to kunernates including: kubernetes namespace, role, secret. These resources are created under different namespace. So the namespace parameter is required, and you can create different deployments under different namespaces. <pre><code>pushd resources/deployment\n./apply.sh --namespace=&lt;namespace-to-deploy&gt;\npopd\n</code></pre></p>"},{"location":"getting-started/deployment/#pushing-images","title":"Pushing Images","text":"<pre><code>gcloud auth configure-docker us-docker.pkg.dev # authenticate to artifact registry\nbazel run //:push_all_images --action_env=namespace=&lt;namespace-to-deploy&gt;\n</code></pre> <p>[!IMPORTANT] the <code>--action_env=namespace=&lt;namespace-to-deploy&gt;</code> flag is required.</p> <p>You can also push images separately by this command. Replace <code>&lt;app&gt;</code> by the directory name under <code>/app</code> (e.g., dcr_api)</p> <pre><code>bazel run //:push_&lt;app&gt;_image --action_env=namespace=&lt;namespace-to-deploy&gt;\n</code></pre>"},{"location":"getting-started/deployment/#deploying-in-google-cloud-platform-gcp","title":"Deploying in Google Cloud Platform (GCP)","text":""},{"location":"getting-started/deployment/#defining-environment-variables","title":"Defining environment variables","text":"<p>First, copy the example environment variables template to the existing directory. <pre><code>cp .env.example env.bzl\n</code></pre> Edit the variables in <code>env.bzl</code>. The <code>env.bzl</code> file is the one that really takes effect, the other files are just templates. The double quotes around a variable name are needed. For example:</p> env.bzl<pre><code>env=\"dev\"                        # the deployment environment\nproject_id=\"you project id\"      # gcp project id\nregion=\"\"                        # the region that the resources created in\nzone=\"\"                          # the zone that the resources created in\n</code></pre>"},{"location":"getting-started/deployment/#deploy","title":"Deploy","text":"<p>Deploy data clean room and jupyterhub by helm chart. <pre><code>source env.bzl\ngcloud container clusters get-credentials dcr-$env-cluster --zone $zone --project $project_id\n\npushd deployment\n./deploy.sh --namespace=&lt;namespace-to-deploy&gt;\npopd\n</code></pre> When deployment is complete, you can follow the output of the script to get the public ip of jupyterhub.  <pre><code>kubectl --namespace=&lt;namespace-to-deploy&gt; get service proxy-public\n</code></pre></p>"},{"location":"getting-started/tutorials/","title":"Tutorials","text":"<p>Coming Soon</p>"}]}